#!/usr/bin/env python3
"""
Multi-MCP Runtime Validation — real subprocess backends, real MCP protocol.

Runs without mocks. Tests every layer that broke in production:
  - tool names (no colons, double-underscore namespacing)
  - inputSchema not empty
  - tool calls actually execute and return correct results
  - multi-backend isolation (calc tools don't bleed to converter and vice-versa)
  - unknown tool returns error, not crash
  - slow backend doesn't hang startup (discovery timeout)
  - SSE transport (port 18099) — tools visible, calls work
"""

import asyncio
import json
import sys
import subprocess
import time
import httpx
from contextlib import AsyncExitStack
from pathlib import Path
from unittest.mock import patch

REPO = Path(__file__).parent
PASS = "✅ PASS"
FAIL = "❌ FAIL"
WARN = "⚠️  WARN"
_results: list[tuple[str, bool, str]] = []


def check(label: str, condition: bool, detail: str = "") -> bool:
    status = PASS if condition else FAIL
    suffix = f"  ({detail})" if detail else ""
    print(f"  {status}: {label}{suffix}")
    _results.append((label, condition, detail))
    return condition


def header(title: str) -> None:
    print(f"\n{'='*65}")
    print(f"  {title}")
    print(f"{'='*65}")


async def run_all() -> int:
    from mcp.client.stdio import StdioServerParameters, stdio_client
    from mcp.client.session import ClientSession
    from mcp import types
    from src.multimcp.mcp_client import MCPClientManager
    from src.multimcp.mcp_proxy import MCPProxyServer

    # ------------------------------------------------------------------ #
    # PHASE 1: Backend server sanity — direct connection, no proxy
    # ------------------------------------------------------------------ #
    header("PHASE 1: Backend sanity (direct stdio, no proxy)")

    calc_path = str(REPO / "tests/tools/calculator.py")
    conv_path = str(REPO / "tests/tools/unit_convertor.py")

    async with AsyncExitStack() as stack:
        cr, cw = await stack.enter_async_context(
            stdio_client(StdioServerParameters(command="python3", args=[calc_path]))
        )
        calc = await stack.enter_async_context(ClientSession(cr, cw))
        await calc.initialize()

        tools_res = await calc.list_tools()
        tnames = [t.name for t in tools_res.tools]
        check("calculator responds", True)
        check("add exists",      "add"      in tnames)
        check("multiply exists", "multiply" in tnames)

        add_tool = next(t for t in tools_res.tools if t.name == "add")
        props = add_tool.inputSchema.get("properties", {})
        check("add has real schema (not empty)", bool(props), str(add_tool.inputSchema))
        check("add schema has 'a'", "a" in props)
        check("add schema has 'b'", "b" in props)

        r = await calc.call_tool("add", {"a": 3, "b": 4})
        out = r.content[0].text if r.content else ""
        check("add(3,4) no error",   not r.isError, out)
        check("add(3,4) == 7",       "7" in str(out), f"got: {out}")

        r = await calc.call_tool("multiply", {"a": 3, "b": 4})
        out = r.content[0].text if r.content else ""
        check("multiply(3,4) == 12", "12" in str(out), f"got: {out}")

    # ------------------------------------------------------------------ #
    # PHASE 2: Proxy passthrough — naming, schemas, routing, calls
    # ------------------------------------------------------------------ #
    header("PHASE 2: Proxy passthrough (tool names, schemas, tool calls)")

    # Use try/except for ExceptionGroup — anyio raises it when stdio_client
    # background reader tasks see their stream closed during stack cleanup.
    # This is expected and benign; the checks already completed successfully.
    try:
      async with AsyncExitStack() as stack:
        cr, cw = await stack.enter_async_context(
            stdio_client(StdioServerParameters(command="python3", args=[calc_path]))
        )
        calc_sess = await stack.enter_async_context(ClientSession(cr, cw))
        await calc_sess.initialize()

        vr, vw = await stack.enter_async_context(
            stdio_client(StdioServerParameters(command="python3", args=[conv_path]))
        )
        conv_sess = await stack.enter_async_context(ClientSession(vr, vw))
        await conv_sess.initialize()

        mgr = MCPClientManager()
        mgr.clients["calc"]      = calc_sess
        mgr.clients["converter"] = conv_sess
        mgr.tool_filters["calc"]      = None
        mgr.tool_filters["converter"] = None

        proxy = MCPProxyServer(mgr)
        await proxy.initialize_single_client("calc",      calc_sess)
        await proxy.initialize_single_client("converter", conv_sess)

        keys = list(proxy.tool_to_server.keys())
        check("calc__add in proxy",                    "calc__add"                         in keys, str(keys))
        check("calc__multiply in proxy",               "calc__multiply"                    in keys)
        check("converter__convert_temperature in proxy","converter__convert_temperature"    in keys)
        check("converter__convert_length in proxy",    "converter__convert_length"         in keys)
        check("exactly 4 tools total",                 len(keys) == 4,                     str(keys))

        # THE historic bug: colons in tool names
        colon_tools = [k for k in keys if ":" in k]
        check("NO colon ':' in any tool name",         len(colon_tools) == 0,
              f"offenders: {colon_tools}" if colon_tools else "clean")

        # All keys split correctly
        bad_split = [k for k in keys if len(k.split("__", 1)) != 2]
        check("all keys split cleanly on '__'",        len(bad_split) == 0,
              f"bad: {bad_split}" if bad_split else "clean")

        # Schema not empty (the fix we just shipped)
        m = proxy.tool_to_server["calc__add"]
        props = m.tool.inputSchema.get("properties", {})
        check("calc__add schema NOT empty",   bool(props), str(m.tool.inputSchema))
        check("calc__add schema has 'a'",     "a" in props)
        check("calc__add schema has 'b'",     "b" in props)

        conv_m = proxy.tool_to_server["converter__convert_temperature"]
        conv_props = conv_m.tool.inputSchema.get("properties", {})
        check("convert_temperature schema has 'value'",    "value"     in conv_props)
        check("convert_temperature schema has 'from_unit'","from_unit" in conv_props)

        # Tool call through proxy — does add actually execute?
        def _out(r) -> str:
            """Extract text from ServerResult.root.content[0].text"""
            try:
                return r.root.content[0].text
            except Exception:
                return str(r)

        def _is_error(r) -> bool:
            try:
                return bool(r.root.isError)
            except Exception:
                return False

        req = types.CallToolRequest(
            method="tools/call",
            params=types.CallToolRequestParams(name="calc__add", arguments={"a": 5, "b": 7}),
        )
        result = await proxy._call_tool(req)
        out = _out(result)
        check("calc__add(5,7) no proxy error", not _is_error(result), out)
        check("calc__add(5,7) == 12",          "12" in str(out), f"got: {out}")

        # Routing isolation — converter tool goes to the right backend
        req2 = types.CallToolRequest(
            method="tools/call",
            params=types.CallToolRequestParams(
                name="converter__convert_temperature",
                arguments={"value": 100.0, "from_unit": "Celsius", "to_unit": "Fahrenheit"},
            ),
        )
        result2 = await proxy._call_tool(req2)
        out2 = _out(result2)
        check("convert_temp(100C→F) no error", not _is_error(result2), out2)
        check("convert_temp(100C→F) == 212",   "212" in out2, f"got: {out2}")

        # multiply — a separate tool going to calc
        req3 = types.CallToolRequest(
            method="tools/call",
            params=types.CallToolRequestParams(name="calc__multiply", arguments={"a": 6, "b": 7}),
        )
        result3 = await proxy._call_tool(req3)
        out3 = _out(result3)
        check("calc__multiply(6,7) == 42",     "42" in str(out3), f"got: {out3}")

        # Unknown tool → graceful error, NOT crash
        req_bad = types.CallToolRequest(
            method="tools/call",
            params=types.CallToolRequestParams(name="nobody__nothing", arguments={}),
        )
        result_bad = await proxy._call_tool(req_bad)
        check("unknown tool returns isError (not crash)", _is_error(result_bad))

    except* Exception as eg:
        # anyio wraps ClosedResourceError from stdio_client cleanup in ExceptionGroup.
        # Only non-ClosedResourceError sub-exceptions are real failures.
        import anyio
        real = [e for e in eg.exceptions if not isinstance(e, anyio.ClosedResourceError)]
        if real:
            check("Phase 2 clean shutdown", False, str(real))
        # else: ClosedResourceError only — expected, benign

    # ------------------------------------------------------------------ #
    # PHASE 3: Discovery timeout — slow backend doesn't hang startup
    # ------------------------------------------------------------------ #
    header("PHASE 3: Discovery timeout (slow server must not hang startup)")

    # Write a backend that sleeps forever during handshake
    slow_script = REPO / "/tmp/slow_mcp_server.py"
    slow_script.parent.mkdir(parents=True, exist_ok=True)
    slow_script = Path("/tmp/slow_mcp_server.py")
    slow_script.write_text("import time\ntime.sleep(9999)\n")

    from src.multimcp.mcp_client import MCPClientManager
    from src.multimcp.yaml_config import MultiMCPConfig, ServerConfig

    mgr2 = MCPClientManager(connection_timeout=3.0)  # 3s timeout for test speed
    config = MultiMCPConfig(servers={
        "slow": ServerConfig(command="python3", args=[str(slow_script)]),
        # A fast server comes AFTER — must not be blocked by slow one
    })

    t0 = time.monotonic()
    discovered = await mgr2.discover_all(config)
    elapsed = time.monotonic() - t0

    check("slow server returns [] (not hang)",  discovered.get("slow") == [],
          f"got: {discovered.get('slow')}")
    check("discovery completes in <10s",        elapsed < 10,
          f"took {elapsed:.1f}s")
    check("discovery respects timeout (~3s)",   elapsed < 7,
          f"took {elapsed:.1f}s (expected ~3s)")

    slow_script.unlink(missing_ok=True)

    # ------------------------------------------------------------------ #
    # PHASE 4: SSE transport (port 18099)
    # ------------------------------------------------------------------ #
    header("PHASE 4: SSE transport (port 18099)")

    # Write a minimal test config pointing at calculator
    test_cfg = Path("/tmp/multi_mcp_runtime_test.json")
    test_cfg.write_text(json.dumps({
        "mcpServers": {
            "calc": {
                "command": "python3",
                "args": [calc_path],
            }
        }
    }))

    # Use a temp YAML dir so we don't pollute the real config
    import tempfile, os
    with tempfile.TemporaryDirectory() as tmpdir:
        tmp_yaml = Path(tmpdir) / "servers.yaml"

        # Patch YAML_CONFIG_PATH so this test doesn't touch the real config
        import src.multimcp.multi_mcp as mm_mod
        original_yaml_path = mm_mod.YAML_CONFIG_PATH
        mm_mod.YAML_CONFIG_PATH = tmp_yaml

        from src.multimcp.multi_mcp import MultiMCP

        server = MultiMCP(transport="sse", host="127.0.0.1", port=18099,
                          config=str(test_cfg))
        server_task = asyncio.create_task(server.run())
        await asyncio.sleep(6)

        # Check if server task already died (e.g. port in use)
        if server_task.done():
            exc = server_task.exception() if not server_task.cancelled() else None
            check("SSE server started successfully", False,
                  f"server died: {exc}" if exc else "server task ended unexpectedly")
            mm_mod.YAML_CONFIG_PATH = original_yaml_path
            test_cfg.unlink(missing_ok=True)
        else:
          try:
            async with httpx.AsyncClient(timeout=5.0) as client:
                # Health check
                r = await client.get("http://127.0.0.1:18099/health")
                check("SSE /health returns 200",       r.status_code == 200, str(r.status_code))
                body = r.json()
                check("SSE /health has status=healthy",body.get("status") == "healthy", str(body))

                # mcp_servers endpoint — pending servers visible
                r2 = await client.get("http://127.0.0.1:18099/mcp_servers")
                check("SSE /mcp_servers returns 200",  r2.status_code == 200)
                body2 = r2.json()
                check("response has active_servers key",  "active_servers"  in body2, str(body2))
                check("response has pending_servers key", "pending_servers" in body2, str(body2))
                all_servers = body2.get("active_servers", []) + body2.get("pending_servers", [])
                check("calc server visible in response",  "calc" in all_servers, str(body2))

                # mcp_tools endpoint
                r3 = await client.get("http://127.0.0.1:18099/mcp_tools")
                check("SSE /mcp_tools returns 200",    r3.status_code == 200)

          except Exception as e:
            check("SSE server reachable",   False, str(e))
          finally:
            server_task.cancel()
            try:
                await server_task
            except (asyncio.CancelledError, SystemExit, BaseException):
                pass
            mm_mod.YAML_CONFIG_PATH = original_yaml_path
            test_cfg.unlink(missing_ok=True)

    # ------------------------------------------------------------------ #
    # PHASE 5: Full MCP protocol over SSE (port 18098)
    # What Copilot CLI / Claude Desktop actually does
    # ------------------------------------------------------------------ #
    header("PHASE 5: Full MCP protocol over SSE (connect via sse_client)")

    import tempfile, os
    test_cfg2 = Path("/tmp/multi_mcp_rt2.json")
    test_cfg2.write_text(json.dumps({
        "mcpServers": {
            "calc": {"command": "python3", "args": [calc_path]},
        }
    }))

    import src.multimcp.multi_mcp as mm_mod
    original_yaml_path = mm_mod.YAML_CONFIG_PATH

    from src.multimcp.multi_mcp import MultiMCP
    from mcp.client.sse import sse_client as mcp_sse_client

    with tempfile.TemporaryDirectory() as tmpdir5:
        mm_mod.YAML_CONFIG_PATH = Path(tmpdir5) / "servers.yaml"
        srv5 = MultiMCP(transport="sse", host="127.0.0.1", port=18098,
                        config=str(test_cfg2))
        task5 = asyncio.create_task(srv5.run())
        await asyncio.sleep(6)

        if task5.done():
            exc5 = task5.exception() if not task5.cancelled() else None
            check("SSE MCP server started (port 18098)", False,
                  f"server died: {exc5}" if exc5 else "ended unexpectedly")
            mm_mod.YAML_CONFIG_PATH = original_yaml_path
            test_cfg2.unlink(missing_ok=True)
        else:
          try:
            async with mcp_sse_client("http://127.0.0.1:18098/sse") as (read, write):
                async with ClientSession(read, write) as mcp_client:
                    init = await mcp_client.initialize()
                    check("SSE MCP initialize succeeds",
                          init.serverInfo.name == "MultiMCP proxy Server",
                          str(init.serverInfo))
                    check("SSE MCP server reports tools capability",
                          init.capabilities.tools is not None)

                    tlist = await mcp_client.list_tools()
                    tool_names = [t.name for t in tlist.tools]
                    check("SSE MCP tools/list returns calc__add",
                          "calc__add" in tool_names, str(tool_names))
                    check("SSE MCP no colon in any tool name",
                          all(":" not in n for n in tool_names),
                          str([n for n in tool_names if ":" in n]))

                    add_t = next((t for t in tlist.tools if t.name == "calc__add"), None)
                    if add_t:
                        props = add_t.inputSchema.get("properties", {})
                        check("SSE MCP calc__add has real schema",
                              bool(props), str(add_t.inputSchema))
                    else:
                        check("SSE MCP calc__add found in list", False)

                    # THE real test: call a tool through SSE MCP protocol
                    call_r = await mcp_client.call_tool("calc__add", {"a": 11, "b": 22})
                    out = call_r.content[0].text if call_r.content else ""
                    check("SSE MCP call_tool no error",    not call_r.isError,   out)
                    check("SSE MCP add(11,22) == 33",      "33" in str(out),     f"got: {out}")

                    call_r2 = await mcp_client.call_tool("calc__multiply", {"a": 7, "b": 8})
                    out2 = call_r2.content[0].text if call_r2.content else ""
                    check("SSE MCP multiply(7,8) == 56",   "56" in str(out2),    f"got: {out2}")

          except Exception as e:
              import anyio
              if isinstance(e, ExceptionGroup):
                  real = [ex for ex in e.exceptions if not isinstance(ex, anyio.ClosedResourceError)]
                  if real:
                      check("SSE MCP protocol test", False, str(real[0]))
              else:
                  check("SSE MCP protocol test", False, str(e))
          finally:
            task5.cancel()
            try: await task5
            except (asyncio.CancelledError, SystemExit, BaseException): pass
            mm_mod.YAML_CONFIG_PATH = original_yaml_path
            test_cfg2.unlink(missing_ok=True)

    # ------------------------------------------------------------------ #
    # PHASE 6: Lazy loading + schema round-trip
    # Tools appear from YAML cache, connect on first call, schema preserved
    # ------------------------------------------------------------------ #
    header("PHASE 6: Lazy loading — tools from YAML cache, connect on first call")

    from src.multimcp.mcp_proxy import MCPProxyServer
    from src.multimcp.yaml_config import MultiMCPConfig, ServerConfig, ToolEntry
    from src.multimcp.cache_manager import get_enabled_tools

    real_schema = {
        "type": "object",
        "properties": {
            "a": {"type": "integer", "title": "A"},
            "b": {"type": "integer", "title": "B"},
        },
        "required": ["a", "b"],
    }
    yaml_cfg = MultiMCPConfig(servers={
        "calc": ServerConfig(
            command="python3",
            args=[calc_path],
            tools={
                "add":      ToolEntry(enabled=True, description="Add two numbers",      input_schema=real_schema),
                "multiply": ToolEntry(enabled=True, description="Multiply two numbers", input_schema=real_schema),
            }
        )
    })

    mgr6 = MCPClientManager()
    # Simulate startup: add as pending (no live connection yet)
    mgr6.add_pending_server("calc", yaml_cfg.servers["calc"].model_dump(exclude_none=True))

    proxy6 = MCPProxyServer(mgr6)
    proxy6.load_tools_from_yaml(yaml_cfg)

    # At this point: tools visible but client=None (lazy)
    cached = proxy6.tool_to_server.get("calc__add")
    check("lazy tool visible before connection", cached is not None)
    check("lazy tool client is None (not yet connected)", cached is not None and cached.client is None)
    check("lazy tool schema preserved from YAML",
          cached is not None and cached.tool.inputSchema.get("properties", {}).get("a") is not None,
          str(cached.tool.inputSchema if cached else "no mapping"))

    # First call triggers lazy connect
    req_lazy = types.CallToolRequest(
        method="tools/call",
        params=types.CallToolRequestParams(name="calc__add", arguments={"a": 100, "b": 200}),
    )
    try:
        result_lazy = await proxy6.initialize_single_client.__func__  # just check
    except Exception:
        pass
    result_lazy = await proxy6._call_tool(req_lazy)
    out_lazy = ""
    try: out_lazy = result_lazy.root.content[0].text
    except Exception: pass
    check("lazy calc__add(100,200) connects and returns 300",
          "300" in str(out_lazy), f"got: {out_lazy}")

    # After call, client is no longer None
    after = proxy6.tool_to_server.get("calc__add")
    check("after lazy call, client is live",
          after is not None and after.client is not None)

    # Clean up lazy connections
    await mgr6.close()

    # ------------------------------------------------------------------ #
    # PHASE 7: Concurrent tool calls — no race conditions
    # ------------------------------------------------------------------ #
    header("PHASE 7: Concurrent tool calls (asyncio.gather — no cross-contamination)")

    async with AsyncExitStack() as stack7:
        cr7, cw7 = await stack7.enter_async_context(
            stdio_client(StdioServerParameters(command="python3", args=[calc_path]))
        )
        sess7 = await stack7.enter_async_context(ClientSession(cr7, cw7))
        await sess7.initialize()

        mgr7 = MCPClientManager()
        mgr7.clients["calc"]     = sess7
        mgr7.tool_filters["calc"] = None
        proxy7 = MCPProxyServer(mgr7)
        await proxy7.initialize_single_client("calc", sess7)

        def make_add_req(a, b):
            return types.CallToolRequest(
                method="tools/call",
                params=types.CallToolRequestParams(name="calc__add", arguments={"a": a, "b": b}),
            )

        # Launch 10 concurrent calls with known results
        pairs = [(i, i*2) for i in range(1, 11)]   # (1,2),(2,4),...,(10,20)
        tasks = [proxy7._call_tool(make_add_req(a, b)) for a, b in pairs]
        results7 = await asyncio.gather(*tasks, return_exceptions=True)

        all_correct = True
        for (a, b), r in zip(pairs, results7):
            if isinstance(r, Exception):
                all_correct = False
                continue
            expected = str(a + b)
            try:
                got = r.root.content[0].text
                if expected not in str(got):
                    all_correct = False
            except Exception:
                all_correct = False

        check("10 concurrent add calls all correct (no cross-contamination)", all_correct,
              f"results: {[getattr(getattr(r,'root',r),'content',r) for r in results7[:3]]}...")

    # ------------------------------------------------------------------ #
    # PHASE 14: Agent-realistic tool sequences
    # Simulates how an AI agent actually uses tools: chained calls, multi-
    # server reasoning, rapid-fire bursts, result-dependent follow-ups,
    # and interleaved error recovery.
    # ------------------------------------------------------------------ #
    header("PHASE 14: Agent-realistic tool sequences (multi-server chains)")

    try:
      async with AsyncExitStack() as stack:
        # Stand up both backends through proxy (same as Phase 2)
        cr, cw = await stack.enter_async_context(
            stdio_client(StdioServerParameters(command="python3", args=[calc_path]))
        )
        calc_sess = await stack.enter_async_context(ClientSession(cr, cw))
        await calc_sess.initialize()

        vr, vw = await stack.enter_async_context(
            stdio_client(StdioServerParameters(command="python3", args=[conv_path]))
        )
        conv_sess = await stack.enter_async_context(ClientSession(vr, vw))
        await conv_sess.initialize()

        mgr14 = MCPClientManager()
        mgr14.clients["calc"]      = calc_sess
        mgr14.clients["converter"] = conv_sess
        mgr14.tool_filters["calc"]      = None
        mgr14.tool_filters["converter"] = None
        proxy14 = MCPProxyServer(mgr14)
        await proxy14.initialize_single_client("calc",      calc_sess)
        await proxy14.initialize_single_client("converter", conv_sess)

        async def _call(tool: str, args: dict):
            req = types.CallToolRequest(
                method="tools/call",
                params=types.CallToolRequestParams(name=tool, arguments=args),
            )
            res = await proxy14._call_tool(req)
            text = str(res.root.content[0].text) if res.root.content else ""
            return text, getattr(res.root, "isError", False)

        # --- 14a: Chained reasoning (agent computes step by step) ---
        # "What is (3+4) * 5?"  →  add(3,4) → multiply(result, 5)
        step1, err1 = await _call("calc__add", {"a": 3, "b": 4})
        check("14a: chain step 1 — add(3,4)=7", step1 == "7" and not err1, step1)
        step2, err2 = await _call("calc__multiply", {"a": int(step1), "b": 5})
        check("14a: chain step 2 — multiply(7,5)=35", step2 == "35" and not err2, step2)

        # --- 14b: Cross-server reasoning ---
        # "Convert 100°C to Fahrenheit, then add 10 to the result"
        temp_raw, terr = await _call("converter__convert_temperature",
            {"value": 100.0, "from_unit": "Celsius", "to_unit": "Fahrenheit"})
        temp_f = float(temp_raw)
        check("14b: cross-server step 1 — 100°C→°F=212", temp_f == 212.0 and not terr,
              str(temp_f))
        added, aerr = await _call("calc__add", {"a": int(temp_f), "b": 10})
        check("14b: cross-server step 2 — 212+10=222", added == "222" and not aerr, added)

        # --- 14c: Rapid-fire parallel burst (agent fires many calls at once) ---
        tasks = [
            _call("calc__add", {"a": i, "b": i * 10}) for i in range(1, 8)
        ]
        burst_results = await asyncio.gather(*tasks)
        burst_ok = all(
            int(txt) == i + i * 10 and not err
            for i, (txt, err) in enumerate(burst_results, 1)
        )
        check("14c: 7 parallel add() calls all correct", burst_ok,
              str([r[0] for r in burst_results]))

        # --- 14d: Parallel across BOTH servers simultaneously ---
        cross_tasks = [
            _call("calc__multiply", {"a": 6, "b": 7}),
            _call("converter__convert_length",
                  {"value": 1.0, "from_unit": "miles", "to_unit": "kilometers"}),
            _call("calc__add", {"a": 100, "b": 200}),
            _call("converter__convert_temperature",
                  {"value": 0.0, "from_unit": "Celsius", "to_unit": "Fahrenheit"}),
        ]
        cr1, cr2, cr3, cr4 = await asyncio.gather(*cross_tasks)
        check("14d: parallel calc__multiply(6,7)=42", cr1[0] == "42" and not cr1[1], cr1[0])
        check("14d: parallel miles→km ≈1.609", abs(float(cr2[0]) - 1.60934) < 0.01, cr2[0])
        check("14d: parallel calc__add(100,200)=300", cr3[0] == "300" and not cr3[1], cr3[0])
        check("14d: parallel 0°C→°F=32", float(cr4[0]) == 32.0 and not cr4[1], cr4[0])

        # --- 14e: Error recovery — bad call then good call (agent retries) ---
        bad_txt, bad_err = await _call("calc__add", {"a": "not_a_number", "b": 5})
        check("14e: bad args returns error", bad_err, f"isError={bad_err}")
        # Agent retries with correct args
        good_txt, good_err = await _call("calc__add", {"a": 99, "b": 1})
        check("14e: retry with good args succeeds", good_txt == "100" and not good_err,
              good_txt)

        # --- 14f: Nonexistent tool then valid tool (agent corrects itself) ---
        ghost_req = types.CallToolRequest(
            method="tools/call",
            params=types.CallToolRequestParams(name="calc__subtract", arguments={"a": 1, "b": 2}),
        )
        ghost_res = await proxy14._call_tool(ghost_req)
        ghost_err = getattr(ghost_res.root, "isError", False)
        check("14f: nonexistent tool returns error gracefully", ghost_err)
        recover_txt, recover_err = await _call("calc__add", {"a": 1, "b": 2})
        check("14f: valid call after ghost tool works", recover_txt == "3" and not recover_err,
              recover_txt)

        # --- 14g: Long chain — 10-step computation ---
        # sum 1+2+3+...+10 by sequential add calls
        running = 0
        chain_ok = True
        for i in range(1, 11):
            txt, err = await _call("calc__add", {"a": running, "b": i})
            running = int(txt)
            if err:
                chain_ok = False
                break
        check("14g: 10-step sequential chain = sum(1..10)=55",
              running == 55 and chain_ok, str(running))

        # --- 14h: tools/list between tool calls (agent refreshes tool list mid-convo) ---
        list_req = types.ListToolsRequest(method="tools/list", params=None)
        list_res = await proxy14._list_tools(list_req)
        tnames14 = [t.name for t in list_res.root.tools]
        check("14h: tools/list mid-conversation returns all 4",
              len(tnames14) == 4 and "calc__add" in tnames14, str(tnames14))
        # Immediately use a tool after listing
        post_list, pl_err = await _call("calc__multiply", {"a": 8, "b": 8})
        check("14h: tool call right after list works", post_list == "64" and not pl_err,
              post_list)

    except* Exception as eg:
        import anyio
        real = [e for e in eg.exceptions if not isinstance(e, anyio.ClosedResourceError)]
        if real:
            check("Phase 14 clean run", False, str(real))


    # ------------------------------------------------------------------ #
    # PHASE 8: Runtime server add via POST /mcp_servers (port 18097)
    # ------------------------------------------------------------------ #
    header("PHASE 8: POST /mcp_servers — add server at runtime, call its tool")

    test_cfg8 = Path("/tmp/multi_mcp_rt8.json")
    test_cfg8.write_text(json.dumps({"mcpServers": {}}))  # Start empty

    with tempfile.TemporaryDirectory() as tmpdir8:
        mm_mod.YAML_CONFIG_PATH = Path(tmpdir8) / "servers.yaml"
        srv8 = MultiMCP(transport="sse", host="127.0.0.1", port=18097,
                        config=str(test_cfg8))
        task8 = asyncio.create_task(srv8.run())
        await asyncio.sleep(5)

        if task8.done():
            exc8 = task8.exception() if not task8.cancelled() else None
            check("Phase 8 SSE server started (port 18097)", False,
                  f"server died: {exc8}" if exc8 else "ended unexpectedly")
            mm_mod.YAML_CONFIG_PATH = original_yaml_path
            test_cfg8.unlink(missing_ok=True)
        else:
          try:
            async with httpx.AsyncClient(timeout=10.0) as hc:
                # Baseline: no servers
                r = await hc.get("http://127.0.0.1:18097/mcp_servers")
                body = r.json()
                # Plugin scanner always adds configured plugins even with empty JSON config —
                # check that runtime_calc specifically is NOT there before we add it
                all8_initial = body.get("active_servers", []) + body.get("pending_servers", [])
                check("runtime_calc not present before POST",
                      "runtime_calc" not in all8_initial, str(body))

                # POST the calculator backend
                add_r = await hc.post("http://127.0.0.1:18097/mcp_servers", json={
                    "mcpServers": {
                        "runtime_calc": {
                            "command": "python3",
                            "args": [calc_path],
                        }
                    }
                })
                check("POST /mcp_servers returns 2xx",
                      200 <= add_r.status_code < 300, str(add_r.status_code))
                await asyncio.sleep(2)  # Let connection establish

                # Verify server appears
                r2 = await hc.get("http://127.0.0.1:18097/mcp_servers")
                body2 = r2.json()
                all8 = body2.get("active_servers", []) + body2.get("pending_servers", [])
                check("runtime_calc appears after POST",
                      "runtime_calc" in all8, str(body2))

                # Verify its tools appear
                tools_r = await hc.get("http://127.0.0.1:18097/mcp_tools")
                tools_body = tools_r.json()
                check("/mcp_tools shows runtime_calc tools",
                      "runtime_calc" in tools_body.get("tools", {}),
                      str(tools_body))

                # DELETE the server
                del_r = await hc.delete("http://127.0.0.1:18097/mcp_servers/runtime_calc")
                check("DELETE /mcp_servers returns 2xx",
                      200 <= del_r.status_code < 300, str(del_r.status_code))
                await asyncio.sleep(1)

                r3 = await hc.get("http://127.0.0.1:18097/mcp_servers")
                body3 = r3.json()
                all8b = body3.get("active_servers", []) + body3.get("pending_servers", [])
                check("runtime_calc gone from both active and pending after DELETE",
                      "runtime_calc" not in all8b, str(body3))

          except Exception as e:
            check("Phase 8 server reachable", False, str(e))
          finally:
            task8.cancel()
            try: await task8
            except (asyncio.CancelledError, SystemExit, BaseException): pass
            mm_mod.YAML_CONFIG_PATH = original_yaml_path
            test_cfg8.unlink(missing_ok=True)

    # ------------------------------------------------------------------ #
    # PHASE 9: Backend crash resilience
    # Kill backend mid-session → graceful isError, not server crash
    # ------------------------------------------------------------------ #
    header("PHASE 9: Backend crash resilience (kill backend, verify graceful error)")

    # Write a backend that exits after first call
    crasher = Path("/tmp/crash_after_one.py")
    crasher.write_text("""
from mcp.server.fastmcp import FastMCP
import sys
mcp = FastMCP("Crasher")

@mcp.tool()
def explode(x: int) -> str:
    \"\"\"Causes the server to exit immediately.\"\"\"
    sys.exit(0)

if __name__ == "__main__":
    mcp.run()
""")

    async with AsyncExitStack() as stack9:
        cr9, cw9 = await stack9.enter_async_context(
            stdio_client(StdioServerParameters(command="python3", args=[str(crasher)]))
        )
        sess9 = await stack9.enter_async_context(ClientSession(cr9, cw9))
        await sess9.initialize()

        mgr9 = MCPClientManager()
        mgr9.clients["crasher"] = sess9
        mgr9.tool_filters["crasher"] = None
        proxy9 = MCPProxyServer(mgr9)
        await proxy9.initialize_single_client("crasher", sess9)

        check("crasher tool discovered", "crasher__explode" in proxy9.tool_to_server)

        # Call the tool — it will cause the backend to sys.exit()
        req9 = types.CallToolRequest(
            method="tools/call",
            params=types.CallToolRequestParams(name="crasher__explode", arguments={"x": 1}),
        )
        # The call may raise or return an error — either way proxy must NOT crash
        try:
            result9 = await proxy9._call_tool(req9)
            # Got a result — it should be an error response
            is_err9 = False
            try: is_err9 = result9.root.isError
            except Exception: is_err9 = True  # Any exception = error = acceptable
            check("crashed backend returns isError (not proxy crash)", True,
                  "proxy survived backend exit")
        except Exception as e:
            # An exception is also acceptable — proxy propagated the error rather than crashing
            check("crashed backend raises (not silent hang)", True, f"raised: {type(e).__name__}")

    crasher.unlink(missing_ok=True)

    # ------------------------------------------------------------------ #
    # PHASE 10: Tool filter — allow/deny lists
    # ------------------------------------------------------------------ #
    header("PHASE 10: Tool filter (allow/deny lists applied correctly)")

    async with AsyncExitStack() as stack10:
        cr10, cw10 = await stack10.enter_async_context(
            stdio_client(StdioServerParameters(command="python3", args=[calc_path]))
        )
        sess10 = await stack10.enter_async_context(ClientSession(cr10, cw10))
        await sess10.initialize()

        # Allow only 'add', deny 'multiply'
        mgr10 = MCPClientManager()
        mgr10.clients["calc"]      = sess10
        mgr10.tool_filters["calc"] = {"allow": ["add"], "deny": []}
        proxy10 = MCPProxyServer(mgr10)
        await proxy10.initialize_single_client("calc", sess10)

        keys10 = list(proxy10.tool_to_server.keys())
        check("allow-list: only calc__add exposed",     "calc__add"      in keys10, str(keys10))
        check("allow-list: calc__multiply filtered out", "calc__multiply" not in keys10, str(keys10))

    async with AsyncExitStack() as stack10b:
        cr10b, cw10b = await stack10b.enter_async_context(
            stdio_client(StdioServerParameters(command="python3", args=[calc_path]))
        )
        sess10b = await stack10b.enter_async_context(ClientSession(cr10b, cw10b))
        await sess10b.initialize()

        # Deny 'add', allow everything else
        mgr10b = MCPClientManager()
        mgr10b.clients["calc"]      = sess10b
        mgr10b.tool_filters["calc"] = {"allow": ["*"], "deny": ["add"]}
        proxy10b = MCPProxyServer(mgr10b)
        await proxy10b.initialize_single_client("calc", sess10b)

        keys10b = list(proxy10b.tool_to_server.keys())
        check("deny-list: calc__multiply exposed",       "calc__multiply"  in keys10b, str(keys10b))
        check("deny-list: calc__add denied",             "calc__add"       not in keys10b, str(keys10b))

    # ------------------------------------------------------------------ #
    # PHASE 11: API key authentication (port 18096)
    # ------------------------------------------------------------------ #
    header("PHASE 11: API key authentication")

    test_cfg11 = Path("/tmp/multi_mcp_rt11.json")
    test_cfg11.write_text(json.dumps({"mcpServers": {}}))

    with tempfile.TemporaryDirectory() as tmpdir11:
        mm_mod.YAML_CONFIG_PATH = Path(tmpdir11) / "servers.yaml"
        srv11 = MultiMCP(transport="sse", host="127.0.0.1", port=18096,
                         api_key="super-secret-test-key",
                         config=str(test_cfg11))
        task11 = asyncio.create_task(srv11.run())
        await asyncio.sleep(5)

        if task11.done():
            exc11 = task11.exception() if not task11.cancelled() else None
            check("Phase 11 auth server started (port 18096)", False,
                  f"server died: {exc11}" if exc11 else "ended unexpectedly")
            mm_mod.YAML_CONFIG_PATH = original_yaml_path
            test_cfg11.unlink(missing_ok=True)
        else:
          try:
            async with httpx.AsyncClient(timeout=5.0) as hc:
                # No auth header → 401
                r = await hc.get("http://127.0.0.1:18096/mcp_servers")
                check("no auth → 401", r.status_code == 401, str(r.status_code))

                # Wrong key → 401
                r2 = await hc.get("http://127.0.0.1:18096/mcp_servers",
                                   headers={"Authorization": "Bearer wrong-key"})
                check("wrong key → 401", r2.status_code == 401, str(r2.status_code))

                # Correct key → 200
                r3 = await hc.get("http://127.0.0.1:18096/mcp_servers",
                                   headers={"Authorization": "Bearer super-secret-test-key"})
                check("correct key → 200", r3.status_code == 200, str(r3.status_code))

                # Malformed Bearer → 401
                r4 = await hc.get("http://127.0.0.1:18096/health",
                                   headers={"Authorization": "Token super-secret-test-key"})
                check("malformed Bearer → 401", r4.status_code == 401, str(r4.status_code))

                # POST with correct auth
                r5 = await hc.post("http://127.0.0.1:18096/mcp_servers",
                                    json={"mcpServers": {}},
                                    headers={"Authorization": "Bearer super-secret-test-key"})
                check("POST with correct key → not 401", r5.status_code != 401, str(r5.status_code))

          except Exception as e:
            check("Phase 11 auth server reachable", False, str(e))
          finally:
            task11.cancel()
            try: await task11
            except (asyncio.CancelledError, SystemExit, BaseException): pass
            mm_mod.YAML_CONFIG_PATH = original_yaml_path
            test_cfg11.unlink(missing_ok=True)

    # ------------------------------------------------------------------ #
    # PHASE 12: inputSchema survives YAML cache round-trip end-to-end
    # Full flow: discover → save → reload → load_tools_from_yaml → check schema
    # ------------------------------------------------------------------ #
    header("PHASE 12: Schema round-trip (discover → YAML save → reload → proxy)")

    from src.multimcp.cache_manager import merge_discovered_tools
    from src.multimcp.yaml_config import save_config, load_config

    with tempfile.TemporaryDirectory() as tmpdir12:
        yaml_path12 = Path(tmpdir12) / "servers.yaml"

        # Step 1: simulate discovery (build config from live server tools)
        async with AsyncExitStack() as stack12:
            cr12, cw12 = await stack12.enter_async_context(
                stdio_client(StdioServerParameters(command="python3", args=[calc_path]))
            )
            sess12 = await stack12.enter_async_context(ClientSession(cr12, cw12))
            await sess12.initialize()

            tools12 = (await sess12.list_tools()).tools

        rt_config = MultiMCPConfig(servers={"calc": ServerConfig(command="python3", args=[calc_path])})
        merge_discovered_tools(rt_config, "calc", tools12)
        save_config(rt_config, yaml_path12)

        # Step 2: reload from YAML (simulates server restart)
        reloaded = load_config(yaml_path12)
        add_entry = reloaded.servers["calc"].tools.get("add")
        check("schema saved to YAML",
              add_entry is not None and add_entry.input_schema is not None,
              str(add_entry))

        # Step 3: build proxy from YAML cache (no live connection)
        mgr12 = MCPClientManager()
        proxy12 = MCPProxyServer(mgr12)
        proxy12.load_tools_from_yaml(reloaded)

        cached12 = proxy12.tool_to_server.get("calc__add")
        check("proxy loaded tool from YAML cache", cached12 is not None)
        props12 = cached12.tool.inputSchema.get("properties", {}) if cached12 else {}
        check("cached tool has real inputSchema (not empty)",
              "a" in props12 and "b" in props12,
              str(cached12.tool.inputSchema if cached12 else "no mapping"))
        check("cached tool has 'required' field",
              "required" in (cached12.tool.inputSchema if cached12 else {}))

    # ------------------------------------------------------------------ #
    # PHASE 13: Real production tools — end-to-end through the proxy
    # Connects to actual installed servers, calls real tools, validates results
    # ------------------------------------------------------------------ #
    header("PHASE 13: Real production tool calls (actual installed backends)")

    from src.multimcp.yaml_config import load_config as load_real_cfg
    real_cfg = load_real_cfg(Path.home() / ".config/multi-mcp/servers.yaml")

    async def _test_server(server_name: str, tool_name: str, arguments: dict,
                           result_validator, description: str) -> None:
        """Connect to a real installed server via the proxy and call a tool."""
        srv = real_cfg.servers.get(server_name)
        if not srv:
            print(f"  ⚠️  SKIP: {server_name} not in YAML (not installed)")
            return

        cmd = srv.command
        args_list = srv.args or []
        if not cmd:
            print(f"  ⚠️  SKIP: {server_name} has no command (URL-only server)")
            return

        try:
            async with AsyncExitStack() as stack:
                params = StdioServerParameters(command=cmd, args=args_list)
                cr, cw = await stack.enter_async_context(
                    asyncio.wait_for(stdio_client(params).__aenter__(), timeout=20)
                    if False else stdio_client(params)
                )
                sess = await stack.enter_async_context(ClientSession(cr, cw))
                await asyncio.wait_for(sess.initialize(), timeout=15)

                mgr = MCPClientManager()
                mgr.clients[server_name] = sess
                mgr.tool_filters[server_name] = None
                proxy = MCPProxyServer(mgr)
                await proxy.initialize_single_client(server_name, sess)

                namespaced = f"{server_name}__{tool_name}"
                if namespaced not in proxy.tool_to_server:
                    check(f"{server_name}: {tool_name} available", False,
                          f"known tools: {list(proxy.tool_to_server.keys())}")
                    return

                req = types.CallToolRequest(
                    method="tools/call",
                    params=types.CallToolRequestParams(
                        name=namespaced, arguments=arguments
                    ),
                )
                result = await asyncio.wait_for(proxy._call_tool(req), timeout=30)
                is_err = False
                raw_out = ""
                try:
                    is_err = result.root.isError
                    raw_out = str(result.root.content[0].text) if result.root.content else ""
                except Exception:
                    raw_out = str(result)

                check(f"{server_name}: {tool_name} no error", not is_err, raw_out[:120])
                check(f"{server_name}: {tool_name} — {description}",
                      result_validator(raw_out), f"got: {raw_out[:120]}")

        except asyncio.TimeoutError:
            print(f"  ⚠️  SKIP: {server_name} timed out (server not reachable)")
        except Exception as e:
            import anyio
            if isinstance(e, ExceptionGroup):
                real_excs = [ex for ex in e.exceptions
                             if not isinstance(ex, anyio.ClosedResourceError)]
                if not real_excs:
                    return  # Only ClosedResourceError on cleanup — fine
                check(f"{server_name}: connects without error", False, str(real_excs[0]))
            else:
                check(f"{server_name}: connects without error", False, str(e))

    # context7 — real documentation lookup (no auth, pure HTTP API)
    await _test_server(
        server_name="context7",
        tool_name="resolve-library-id",
        arguments={"libraryName": "react", "query": "React hooks useState"},
        result_validator=lambda out: "/" in out and len(out) > 3,
        description="returns a library ID path (e.g. /facebook/react)",
    )

    # serena — local filesystem, no auth needed
    await _test_server(
        server_name="serena",
        tool_name="list_dir",
        arguments={"relative_path": ".", "recursive": False},
        result_validator=lambda out: len(out) > 10,  # any non-trivial output
        description="returns directory listing",
    )

    # sequential-thinking — pure computation, no external dependencies
    await _test_server(
        server_name="sequential-thinking",
        tool_name="sequentialthinking",
        arguments={
            "thought": "Testing the proxy",
            "nextThoughtNeeded": False,
            "thoughtNumber": 1,
            "totalThoughts": 1,
        },
        result_validator=lambda out: len(out) > 0,
        description="returns structured thinking output",
    )

    # ------------------------------------------------------------------ #
    # PHASE 14: GitHub MCP tools through the proxy (Docker backend)
    # ------------------------------------------------------------------ #
    header("PHASE 14: GitHub MCP tools (Docker → stdio → proxy → tool call)")

    gh_srv = real_cfg.servers.get("github")
    if not gh_srv or not gh_srv.command:
        print("  ⚠️  SKIP: github not in YAML or has no command")
    else:
        try:
            async with AsyncExitStack() as stack:
                params = StdioServerParameters(command=gh_srv.command, args=gh_srv.args or [])
                cr, cw = await stack.enter_async_context(stdio_client(params))
                sess = await stack.enter_async_context(ClientSession(cr, cw))
                await asyncio.wait_for(sess.initialize(), timeout=30)

                tools = (await sess.list_tools()).tools
                check("github: server connects via Docker",   True)
                check("github: 38 tools available",          len(tools) == 38, f"got {len(tools)}")

                # Wire through proxy
                mgr_gh = MCPClientManager()
                mgr_gh.clients["github"] = sess
                mgr_gh.tool_filters["github"] = None
                proxy_gh = MCPProxyServer(mgr_gh)
                await proxy_gh.initialize_single_client("github", sess)

                gh_keys = [k for k in proxy_gh.tool_to_server if k.startswith("github__")]
                check("proxy exposes github__ tools",        len(gh_keys) > 0, str(len(gh_keys)))
                check("no colon in any github tool name",    all(":" not in k for k in gh_keys),
                      str([k for k in gh_keys if ":" in k]))

                # get_me — returns authenticated user (read-only, no params)
                req_me = types.CallToolRequest(
                    method="tools/call",
                    params=types.CallToolRequestParams(name="github__get_me", arguments={}),
                )
                r_me = await asyncio.wait_for(proxy_gh._call_tool(req_me), timeout=15)
                out_me = ""
                try: out_me = r_me.root.content[0].text
                except Exception: pass
                check("github__get_me no error",             not r_me.root.isError, out_me[:80])
                check("github__get_me returns login field",  '"login"' in out_me, out_me[:120])

                # search_repositories — search public repos
                req_sr = types.CallToolRequest(
                    method="tools/call",
                    params=types.CallToolRequestParams(
                        name="github__search_repositories",
                        arguments={"query": "multi-mcp", "perPage": 3},
                    ),
                )
                r_sr = await asyncio.wait_for(proxy_gh._call_tool(req_sr), timeout=15)
                out_sr = ""
                try: out_sr = r_sr.root.content[0].text
                except Exception: pass
                check("github__search_repositories no error", not r_sr.root.isError, out_sr[:80])
                check("github__search_repositories returns results",
                      "total_count" in out_sr or "items" in out_sr, out_sr[:120])

                # list_branches on this very repo
                req_lb = types.CallToolRequest(
                    method="tools/call",
                    params=types.CallToolRequestParams(
                        name="github__list_branches",
                        arguments={"owner": "itstanner5216", "repo": "multi-mcp"},
                    ),
                )
                r_lb = await asyncio.wait_for(proxy_gh._call_tool(req_lb), timeout=15)
                out_lb = ""
                try: out_lb = r_lb.root.content[0].text
                except Exception: pass
                check("github__list_branches no error",      not r_lb.root.isError, out_lb[:80])
                check("github__list_branches finds branches", "stabilize" in out_lb or "main" in out_lb,
                      out_lb[:200])

        except asyncio.TimeoutError:
            print("  ⚠️  SKIP: GitHub Docker container timed out")
        except Exception as e:
            import anyio
            if isinstance(e, ExceptionGroup):
                real_excs = [ex for ex in e.exceptions
                             if not isinstance(ex, anyio.ClosedResourceError)]
                if real_excs:
                    check("github: connects without error", False, str(real_excs[0]))
            else:
                check("github: connects without error", False, str(e))

    # ------------------------------------------------------------------ #
    # Summary
    # ------------------------------------------------------------------ #
    print(f"\n{'='*65}")
    total   = len(_results)
    passed  = sum(1 for _, ok, _ in _results if ok)
    failed  = total - passed
    print(f"  RESULT: {passed}/{total} checks passed  ({failed} failed)")
    if failed:
        print("\n  Failed checks:")
        for label, ok, detail in _results:
            if not ok:
                print(f"    ❌ {label}" + (f"  ({detail})" if detail else ""))
    print(f"{'='*65}\n")
    return 0 if failed == 0 else 1


if __name__ == "__main__":
    sys.exit(asyncio.run(run_all()))
